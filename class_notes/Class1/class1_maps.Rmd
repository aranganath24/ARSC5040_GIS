---
title: "Choropleth Maps in R Studio"
author: "Aditya Ranganath"
date: "3/26/2022"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
    number_sections: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

In this tutorial, we'll explore how to use R Studio as a mapping application, by drawing on the *tmap* package (among other packages). In our applied example, we'll focus on taking an indicator from the [World Bank's Development Indicators](https://datatopics.worldbank.org/world-development-indicators/) (a widely used collection of cross-national time-series data on economic development), and displaying this indicator on a world map. More specifically, we will be making a choropleth map; choropleths are only one of many different kinds of maps out there, but they are widely used in the social sciences, since so much of our data is connected with enumeration units (like census tracts, counties, countries etc.). For a good primer on choropleth maps, please see this [guide](https://www.axismaps.com/guide/choropleth).

In working through the example below, you will become familiar with the basic mechanics of a simple, yet fundamentally important GIS workflow: the process of joining a conventional tabular dataset (that is, a dataset without explicit spatial coordinates attached to it) to a spatial dataset (that is, an explicitly georeferenced dataset), with a view towards displaying information from the tabular dataset on the geographic boundaries delineated by the spatial dataset. 

Why map the information in tabular datasets to begin with? To some extent, for the same reason we attempt to make a visualization of any kind. It can help to communicate information; it can help us identify patterns we wouldn't have otherwise noticed; and it can suggest novel hypotheses. More specifically, making a map might alert us to the spatial dimensions of the social phenomenon we are investigating, which might affect our methodological or substantive approach to a given research problem. Just as good social scientists try to contextualize their social process or outcome of interest in time, it is also important to contextualize it in space; making a map is often the first step in this process. 

It is important to underscore that this tutorial is not an introduction to cartography, which is an art unto itself, and beyond our scope. However, the tutorial will show you how to customize maps in R, and you can use these skills (after reading up on cartography on your own) to make maps that conform to sound cartographic design principles. Our goal here is not to make works of art, but rather to learn how to quickly create functional and informative choropleth maps that are useful to social scientists.

For more on principles of cartographic design, a good place to start is this accessible [guide](https://www.axismaps.com/guide) from Axis Maps. As you begin to make different types of maps (or more sophisticated ones, with more moving parts than a standard choropleth map), you may want to begin with these resources from Esri: [Design Principles for Cartography](https://www.esri.com/arcgis-blog/products/product/mapping/design-principles-for-cartography/) and [Make Maps People Want to Look At](https://www.esri.com/news/arcuser/0112/make-maps-people-want-to-look-at.html), both by Aileen Buckley.  

# Preliminaries

R is an open-source programming language for statistical computing that allows users to carry out a wide range of data analysis and visualization tasks (among other things). One of the big advantages of using R is that it has a very large user community among social scientists and statisticians, who frequently publish R packages. One might think of packages as workbooks of sorts, which contain a well-integrated set of R functions, scripts, data, and documentation; these “workbooks” are designed to facilitate certain tasks or implement given procedures. These packages are then shared with the broader community, and at this point, anyone who needs to accomplish the tasks to which the package addresses itself can use the package in the context of their own projects. The ability to use published packages considerably simplifies the work of applied social scientists using R; it means that they rarely have to write code entirely from scratch, and can build on the code that others have published in the form of packages. This allows applied researchers to focus on substantive problems, without having to get too bogged down in complicated programming tasks.

In the context of this tutorial, generating choropleth maps based on the World Development Indicators (WDI) data would be relatively complex if we had to write all our code from scratch. However, because we are able to make use of mapping and visualization packages written by other researchers, the task is considerably simpler, and will not require any complicated programming.

In order to process our data and make our maps, we will use a variety of packages. They are:

* *WDI*: It is possible to download our WDI variable of choice directly from the World Bank's WDI [website](https://datatopics.worldbank.org/world-development-indicators/) (see the "Access Data" section), but there is an R package, entitled *WDI*, that allows users to directly query and extract WDI data without leaving R. Since this is more convenient than downloading the dataset externally and loading it into R, we will use the *WDI* package to extract the WDI series of our choice. 
* sf*: The sf package allows us to work with spatially explicit data in R. In particular, it allows us to work with "sf" objects. "sf" stands for "simple features", and is a data structure that is able to store and display geospatial vector data. Vector data (along with raster) is one of the two main types of GIS data (along with raster data), and we'll discuss it in more detail next class. 
* *tmap*: The *tmap* package will allow us to create and customize our map. It has become one of the major R mapping packages in use today. There are other package that facilitate mapping in R. One prominent alternative to *tmap*, which many of you may be familiar with, is *ggplot2*. However, while *tmap* uses very similar syntax to *ggplot2*, the former is a dedicated mapping package, while the latter is a more general-purpose visualization package. In my experience, *tmap* is slightly more intuitive and user-friendly, so we will use it instead of *ggplot2* in this tutorial.
* *rnaturalearth* and *rnaturalearthdata*:  In order to visualize our data on a world map, we need a spatial dataset of the world’s country boundaries. One way to get such a dataset is to download it from a public repository, and then load it into R Studio. However, these packages allow us to load a spatial dataset of world boundaries into R Studio as sf objects without having to actually download anything, which effectively saves us a few steps in the workflow.
* *tidyverse*: The *tidyverse* is a suite of data-science packages (*ggplot2*, mentioned above, is actually a part of the tidyverse) that provide useful functions to implement common data science/data analysis tasks. We'll use some *tidyverse* packages to clean up our data, subset data implement table joins etc. 
* *grid*: The *grid* package allows us to customize the layout of our maps, and in particular, make inset maps (an inset map is a smaller map embedded within the frame of the main map; it can be used to contextualize a given map, or to provide a "zoomed in" view of a particularly important part of the main map, or a part of the main map that is difficult to see). 

To install a package in R, pass the name of the package (within quotation marks) to the ```install.packages()``` function. For example, let's say you don't have *tmap* installed. You can install it with the following:

```{r, eval=F}
# Installs tmap packages
install.packages("tmap")
```

A function is essentially a programming construct that takes a specified input, runs this input (called an “argument”) through a set of procedures, and returns an output. In the code block above, the name of the package we wanted to install (here, “tmap”) was enclosed within quotation marks and passed as an argument to ```install.packages```; this effectively downloaded the *tmap* package to your computer. 

Repeat that process for any packages you don't have installed. 

After all the packages are downloaded, we must load them into memory. We can think of the process of loading installed packages into a current R environment as analogous to opening up an application on your phone or computer after it has been installed (even after an application has been installed, you can’t use it until you open it!). To load (i.e. “open”) an R package, we pass the name of the package we want to load as an argument to the ```library()``` function. Below, we load all of the required packages into memory: 

```{r, message=F, warning=F}
# Loads required libraries
library(WDI)
library(sf)
library(tmap)
library(rnaturalearth)
library(rnaturalearthdata)
library(tidyverse)
library(grid)
```

At this point, the packages are loaded and ready to go! One important thing to note regarding the installation and loading of packages is that we only have to install packages once; after a package is installed, there is no need to subsequently reinstall it. However, we must load the packages we need (using the library function) every time we open a new R session. In other words, if we were to close R Studio at this point and open it up later, we would **not** need to install these packages again, but **would** need to load the packages again (3.5).

Note that the codeblocks in this tutorial usually have comments, prefaced by a hash (“#”). When writing code in R (or any other command-line interface) it is good practice to preface one’s code with brief comments that describe what a block of code is doing. Writing these comments can allow someone else (or your future self) to read and quickly understand the code more easily than otherwise might be the case. The hash before the comment effectively tells R that the subsequent text is a comment, and should be ignored when running a script If one does not preface the comment with a hash, R wouldn’t know to ignore the comment, and would throw an error message.

```{r, echo=F, warning=F, message=F}
library(DT) 
```

# Load Required Data

Now that we've taken care of these preliminary steps, let's go ahead and load our data into R Studio. Below, we'll first load in a spatial dataset of world boundaries, and then read in our World Bank dataset using the *WDI* package.

Before proceeding, however, it is useful to briefly consider the concept of object asssignment, which will make the subsequent sections easier to follow. Consider the following example:

```{r}
# assign value 5 to new object named x
x<-5
```

In the code above, we used R's assignment operator (```<-```, i.e. a left-facing arrow) to assign value 5 to an object named “x.” Now that an object named “x” has been created and assigned the value 5, printing “x” in our console (or printing “x” in our script and running it) will return the value 5:

```{r}
# Print value assigned to object "x"
x
```

More generally, the process of assignment effectively equates the output created by the code on the right side of the assignment operator (```<-```) to an object with a name that is specified on the left side of the assignment operator. Whenever we want to look at the value assigned to an object (i.e. the output created by the code to the right side of the assignment operator), we simply print the name of the object in the R console (or print the name and run it within a script).

While the example above was very simple, we can assign virtually any R code, and by extension, the data structure(s) generated by that code (such as datasets, maps, graphs) to an R object. Indeed, we’ll use the basic principle of object assignment introduced above to assign the datasets we'll import below to new objects. Note that object names are arbitrary and could be virtually anything, but it is good practice for object names to describe their contents. If this is new, it will begin to make more sense as we go. 

## Load and process the spatial dataset of country boundaries

## Load the spatial dataset of country boundaries into R and assign to new object

When working with spatial data in R, we will sometimes want to import data that is stored on our computer. There are several functions in the sf package that will allow us to easily import saved or downloaded spatial data into R; the most commonly used ```sf``` package function to load saved spatial vector data into R is the ```st_read()``` function. For more details, please consult the ```st_read()``` function's documentation by typing ```?st_read()```. 

In our case, however, we won’t have to download and import the spatial data we need into R Studio from our computer’s local drive. That is because there are R packages that already provide this spatial data, and allow us to directly load it into memory. In particular, we’ll use the ```ne_countries()``` function of the rnaturalearth package to bring a spatial dataset of country borders into our R environment, and then assign it to an object that we will name ```country_boundaries```:

```{r}
# Brings spatial dataset of country boundaries into R environment using the rnaturalearth package, and then assigns this spatial dataset to an object named "country_boundaries"
country_boundaries<-ne_countries(scale="medium", returnclass="sf")
```

Note the two arguments we pass to the ne_countries function: the "scale" argument specifies that we want to use a medium scale when rendering the map (the other options are ‘small’ and ‘large’), while the "returnclass" argument specifies that we want the spatial dataset as an sf object. 

### Explore the spatial dataset

Now that we have our spatial dataset loaded into our R environment and assigned to ```country_boundaries```, let's open up this dataset and see what it looks like. The best way to view a dataset in R studio is to pass the name of the relevant object to the ```View()``` function, which will open up the dataset in R Studio's built-in data viewer.

```{r}
# View "country_boundaries" data in R Studio Data Viewer
View(country_boundaries)
```

```{r, echo=F, warning=F}
country_boundaries_view<-country_boundaries %>% 
                          relocate(name_long, geometry, iso_a3, featurecla, type,
                                   region_un)

country_boundaries_view %>% datatable(extensions=c("Scroller", "FixedColumns"), options = list(
  deferRender = TRUE,
  scrollY = 350,
  scrollX = 350,
  dom = "t",
  scroller = TRUE,
  fixedColumns = list(leftColumns = 3)
))
```

By scrolling across the dataset, you'll note that each row corresponds to a country, and that there are many columns that correspond to various country-level attributes. The crucial column, however, which makes this a spatial dataset (as opposed to merely a tabular one), is the information contained in a column called “geometry”. This column contains geographic coordinate information that essentially defines a polygon for each country in the dataset. Note that the “geometry” column is likely one of the last columns in dataset, so you may have to scroll a bit to find it.

To observe the information in the "geometry" column more clearly, we can extract that specific column. The dollar sign (```$```) is the R operator that allows us to extract a specified column; below, we are extracting the "geometry" column from the dataset assigned to the ```country_boundaries``` object:

```{r}
# Extracts "geometry" column from country_boundaries
country_boundaries$geometry
```

Note that extracting the "geometry" column prints some useful metadata; it tells us that the dataset has 241 features, and that it represents spatial information as polygons (geometry type: MULTIPOLYGON). It also provides information on the datasets bounding box ("bbox") and coordinate reference system ("CRS"). We'll unpack this information a bit more next class, but for now, what is important to notice is that the "geometry" column is comprised of multiple geographic coordinates for each row; we can use this information in the “geometry” column to draw georeferenced polygons for each row in the spatial dataset, which will yield a world map! 

### Use information from the "geometry" column to render a map

To translate the information in the "geometry" column of the dataset into a cartographic representation, we’ll use the *tmap* package. In particular, we’ll use the ```tm_shape``` and ```tm_polygons``` functions from *tmap*, which are connected by a plus sign (+). The argument passed to the ```tm_shape``` function is the name of the object associated with the spatial dataset (```country_boundaries```, defined above). In addition, the tm_polygons function indicates that the spatial data is to be represented using polygons (as opposed to alternatives such as lines or points), and does not require any arguments (we'll add some arguments in just a bit). When we type in and run the following code from our script, the result is a map that is rendered based on the information in the “geometry” column of country_boundaries:

```{r, fig.asp=0.5}
# maps geographic features (i.e. countries) of "country_boundaries" using tmap package functions
tm_shape(country_boundaries)+
  tm_polygons()
```

If you don't like the grey polygons, you can specify a desired color within the ```tm_polygons()``` function. For guidance on working with colors in R (including information on color and palette codes), see this extremely useful [R Color Cheatsheet](https://www.nceas.ucsb.edu/sites/default/files/2020-04/colorPaletteCheatsheet.pdf), by Melanie Frazier. 

For example, let's say we want to draw the polygons in the color associated with "darkorange" on the cheat sheet. We can use the following:

```{r, fig.asp=0.5}
# maps geographic features (i.e. countries) of "country_boundaries" using tmap package functions; polygons rendered in "darkorange"
tm_shape(country_boundaries)+
  tm_polygons("darkorange")
```

Or, say we prefer the color associated with the label "cadetblue2":

```{r, fig.asp=0.5}
# Maps country polygons from "country_boundaries" in "cyan1"
tm_shape(country_boundaries)+
  tm_polygons("cadetblue2")
```

Just as we can assign datasets or numeric values to objects, so too with maps. For example, let's say we want to assign the orange world map we generated above to an object named ```world_map_orange```:

```{r}
world_map_orange<-tm_shape(country_boundaries)+
                      tm_polygons("darkorange")
```

Now, whenever we want to bring up that particular map, we can simply print the name of the object, and the map will render in the "Plots" tab of the R Studio interface (on the bottom-right of the screen):

```{r, fig.asp=0.5}
# prints contents of "world_map_orange"
world_map_orange
```

### Make an interactive map

One of the nice things about *tmap* is that it allows us to toggle back and forth between static print maps, and dynamic interactive maps that allow users to zoom in/out, pan around, view attribute characteristics etc. All you have to do to generate an interactive map is use the ```tmap_mode()``` function to shift into "view" mode with the following:

```{r}
# set tmap mode to "view"
tmap_mode("view")
```

Now, our *tmap* code outputs will yield a dynamic map:

```{r}
# prints contents of "world_map_orange" in "view" mode
world_map_orange
```

This map can easily be saved as an html document, and subsequently embedded on a website. 

If we want to shift back to a static map, simply switch back to "plot" mode via the same ```tmap_mode``` function:

```{r}
# set tmap mode to "plot"
tmap_mode("plot")
```

Now, our *tmap* code will once again yield a static representation of the spatial information embedded in ```country_boundaries```:

```{r, fig.asp=0.5}
# prints contents of "world_map_orange" in print mode
world_map_orange
```

### Editing spatial datasets

We can edit spatial datasets in R Studio with relative ease, using commonly-used R packages. Let’s say, for example, that we don’t want Antarctica to appear on our map (since Antarctica typically does not appear on political maps of the world).

To delete Antarctica from the map, we first need to delete the row that corresponds to Antarctica in ```country_boundaries```. We can do so with the following code:

```{r}
# Deletes Antarctica from "country_boundaries"
country_boundaries<-country_boundaries %>% filter(iso_a3 !="ATA")
```

We can translate the code above into ordinary language as follows: “Take the existing country boundaries dataset (```country_boundaries``` to the left of the ```%>%``` and to the right of the assignment operator) and then (```%>%```, a symbol called a pipe, which is used to chain together code) select only the countries that are not Antarctica (```filter(iso_a3 !="ATA"```). Take this amended (sans Antarctica) spatial dataset, and assign it back to an object named ```country_boundaries``` (```country_boundaries<-```); this assignment effectively overwrites the previous dataset that was assigned to country_boundaries (which did include Antarctica) with the amended (sans-Antarctica) dataset.”

Two things may require additional elaboration:

* First is the pipe, the symbol that looks like this: ```%>%```. The pipe operator essentially takes the output of the code on its left, and then use that output as an input to the code on its right. Here, the pipe takes the ```country_boundaries``` spatial object on its left, and then feeds this data into the ```filter()``` function on its right. In other words, the pipe operator links the code on its two sides, and establishes that the data to be “filtered” within the filter function is ```country_boundaries```.
* The ```filter()``` function is a function from the *dplyr* package that allows one to select rows from a dataset using specified criteria. In our case, we want to select all rows from the dataset that are not Antarctica. The argument passed to the filter function, ```iso_a3 !="ATA"```, is essentially saying “return any records where the”iso_a3” variable (i.e. the 3 digit ISO country code) in the attribute table is NOT equal to “ATA” (Antarctica’s code). Note that != is R syntax for “not equal to”. If we were to instead type filter(iso_a3=="ATA), the function would only select the Antarctica row from the dataset and discard everything else.

Now, let's go ahead an map the revised ```country_boundaries``` object:

```{r}
tm_shape(country_boundaries)+
  tm_polygons()
```

Notice that Antarctica is no longer mapped, since the Antarctica record is no longer in the 
```country_boundaries``` object that contains the underlying data. 

## Use the *WDI* package to extract development indicator to be mapped

Now that we've loaded our spatial dataset into R Studio and become acquainted with the information it contains, let's turn to the process of extracting development indicator data using the *WDI* package. We'll extract an indicator we're interested in mapping; then, below, we'll join this indicator to our spatial dataset (```country_boundaries```) based on a common field. Once the WDI data is in our spatial dataset, we can represent country-level variation in the WDI indicator on the associated map. 

Let's first get a sense of what variables are available as part of the World Bank Development Indicators data series. We can extract variables in the series, along with their associated codes, using the ```WDIsearch()``` function. Below, we don't pass any arguments to ```WDIsearch```, so it will return a table containing *all* of the variables in the development indicator data series. We'll assign this table to a new object named ```WDI_variables```:

```{r}
# Extracts variable names and codes for development indicator series, and assigns it to a new object named "WDI_variables"
WDI_variables<-WDIsearch()
```

Now, let's view the extracted information in the R Studio data viewer by calling the ```View()``` function:

```{r}
# Views data assigned to "WDI_variables" in data viewer
View(WDI_variables)
```

```{r, echo=F, warning=F}
WDI_variables %>% datatable(extensions=c("Scroller", "FixedColumns"), options = list(
  deferRender = TRUE,
  scrollY = 350,
  scrollX = 350,
  dom = "t",
  scroller = TRUE,
  fixedColumns = list(leftColumns = 3)
))
```

Now that you've extracted this table of variable names and codes, scroll through and decide which one you'd like to represent on a world map. 

In 







```{r}
trade_gdp_string<-"NE.TRD.GNFS.ZS"
```

## Extract WDI data

```{r}
trade_gdp_2010_2018<-WDI(country="all",
                                indicator=trade_gdp_string,
                                start=2010,
                                end=2018,
                                extra=T)
```

```{r}
trade_gdp_2015<-trade_gdp_2010_2018 %>% 
                  filter(year=="2015")
```

```{r}
View(trade_gdp_2015)
```

```{r, echo=F}
trade_gdp_2015 %>% datatable(extensions=c("Scroller", "FixedColumns"), options = list(
  deferRender = TRUE,
  scrollY = 350,
  scrollX = 350,
  dom = "t",
  scroller = TRUE,
  fixedColumns = list(leftColumns = 3)
))
```

## Join WDI data to spatial dataset

```{r}
trade_2015_spatial<-full_join(country_boundaries, trade_gdp_2015,
                                    by=c("iso_a3"="iso3c"))
```

```{r, echo=F}
trade_2015_spatial_truncated<-trade_2015_spatial %>% 
                               select(country, iso_a3, NE.TRD.GNFS.ZS, year, geometry)
```

```{r}
View(trade_2015_spatial)
```

```{r, echo=F}
trade_2015_spatial_truncated %>% datatable(extensions=c("Scroller", "FixedColumns"), options = list(
  deferRender = TRUE,
  scrollY = 350,
  scrollX = 350,
  dom = "t",
  scroller = TRUE,
  fixedColumns = list(leftColumns = 3)
))
```

```{r}
trade_2015_spatial<-trade_2015_spatial %>% 
                      rename(trade_pct_gdp=NE.TRD.GNFS.ZS)
```

## Make map of WDI data

```{r}
tm_shape(trade_2015_spatial)+
  tm_polygons(col="trade_pct_gdp", palette="YlOrRd", style="jenks",
              n=5)
```
## Make map with inset map

```{r}
unique(trade_2015_spatial$subregion)
```

```{r}
trade_2015_spatial_sea<-trade_2015_spatial %>% 
                            filter(subregion=="South-Eastern Asia")

y<-tm_shape(trade_2015_spatial_sea)+
  tm_polygons(col="trade_pct_gdp", palette="YlOrRd", style="jenks",
              n=5)

y
```

```{r}
library(grid)
x<-tm_shape(trade_2015_spatial)+
  tm_polygons(col="trade_pct_gdp", palette="YlOrRd", style="jenks",
              n=5)
x
print(y, vp = viewport(0.8, 0.27, width = 0.5, height = 0.5))
```


```{r}
library(grid)
x<-tm_shape(trade_2015_spatial)+
  tm_polygons(col="trade_pct_gdp", palette="YlOrRd", style="jenks",
              n=5)
x
print(y, vp = viewport(0.8, 0.18, width = 0.3, height = 0.3))
```
## Map change over time

```{r}
trade_gdp_2010_2015<-trade_gdp_2010_2018 %>% 
                      filter(year=="2010"|year=="2015")
```


```{r}
trade_gdp_2010_2015_wide<-trade_gdp_2010_2015 %>% 
                          pivot_wider(names_from=year, values_from=c(NE.TRD.GNFS.ZS))
```

```{r}
trade_gdp_2010_2015_wide<-trade_gdp_2010_2015_wide %>% 
                            rename("trade_gdp_2015"="2015") %>% 
                            rename("trade_gdp_2010"="2010")
```


```{r}
trade_gdp_2010_2015_wide<-trade_gdp_2010_2015_wide %>% 
                          mutate("2015_2010_pctpt_difference"=(trade_gdp_2015-trade_gdp_2010))
```

```{r}
trade_gdp_2010_2015_wide_spatial<-full_join(country_boundaries, trade_gdp_2010_2015_wide,
                                    by=c("iso_a3"="iso3c"))
```

```{r}
tm_shape(trade_gdp_2010_2015_wide_spatial)+
  tm_polygons(col="2015_2010_pctpt_difference", palette="Greens", style="jenks",
              n=5, midpoint=T)
```



https://ecodiv.earth/post/creating-a-map-with-inset-using-tmap/

# Country-Level Map

# USA Local Map 

# Foreign Local Map 


https://datacatalog.worldbank.org/search/dataset/0041418

https://databank.worldbank.org/reports.aspx?dsid=41&series=IN.ENV.PM.CONC#



